## Algorithms
- [x] [Deep Q-Network](https://arxiv.org/abs/1312.5602)
- [x] [Double Deep Q-Network](https://arxiv.org/abs/1509.06461)
- [x] [Dueling Deep Q-Network](https://arxiv.org/abs/1511.06581)
- [x] [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952)
- [x] [Noisy Networks for Exploration](https://arxiv.org/abs/1706.10295)
- [x] [Rainbow](https://arxiv.org/abs/1710.02298)
- [x] [Proximal Policy Optimization](https://arxiv.org/abs/1707.06347)
- [x] [Soft Actor Critic](https://arxiv.org/abs/1801.01290)
- [x] [Twin Delayed Deep Deterministic Policy Gradient](https://arxiv.org/abs/1802.09477)
- [x] [Distributed Distributional Deterministic Policy Gradients](https://arxiv.org/abs/1804.08617)
- [x] [Distributed Prioritized Experience Replay](https://arxiv.org/abs/1803.00933)
- [x] [Distributed Rainbow](https://arxiv.org/abs/1803.00933)
- [x] [Distributed Proximal Policy Optimization](https://arxiv.org/abs/1707.06347)
- [x] [Distributed Soft Actor Critic](https://arxiv.org/abs/1801.01290)
- [x] [Distributed Twin Delayed Deep Deterministic Policy Gradient](https://arxiv.org/abs/1802.09477)
- [x] [Distributed Distributional Deterministic Policy Gradients](https://arxiv.org/abs/1804.08617)
- [x] [Distributed Noisy Networks for Exploration](https://arxiv.org/abs/1706.10295)
- [x] [Distributed Dueling Deep Q-Network](https://arxiv.org/abs/1511.06581)
- [x] [Distributed Double Deep Q-Network](https://arxiv.org/abs/1509.06461)
- [x] [Distributed Deep Q-Network](https://arxiv.org/abs/1312.5602)
- [x] [Distributed Prioritized Experience Replay](https://arxiv.org/abs/1511.05952)
- [x] [Distributed Rainbow](https://arxiv.org/abs/1710.02298)
- [x] [Distributed Proximal Policy Optimization](https://arxiv.org/abs/1707.06347)
- [x] [Distributed Soft Actor Critic](https://arxiv.org/abs/1801.01290)
- [x] [Distributed Twin Delayed Deep Deterministic Policy Gradient](https://arxiv.org/abs/1802.09477)
- [x] [Distributed Distributional Deterministic Policy Gradients](https://arxiv.org/abs/1804.08617)
- [x] [Distributed Noisy Networks for Exploration](https://arxiv.org/abs/1706.10295)
- [x] [Distributed Dueling Deep Q-Network](https://arxiv.org/abs/1511.06581)
- [x] [Distributed Double Deep Q-Network](https://arxiv.org/abs/1509.06461)
- [x] [Distributed Deep Q-Network](https://arxiv.org/abs/1312.5602)
- [x] [Distributed Prioritized Experience Replay](https://arxiv.org/abs/1511.05952)
- [x] [Distributed Rainbow](https://arxiv.org/abs/1710.02298)
- [x] [Distributed Proximal Policy Optimization](https://arxiv.org/abs/1707.06347)
- [x] [Distributed Soft Actor Critic](https://arxiv.org/abs/1801.01290)
- [x] [Distributed Twin Delayed Deep Deterministic Policy Gradient](https://arxiv.org/abs/1802.09477)
- [x] [Distributed Distributional Deterministic Policy Gradients](https://arxiv.org/abs/1804.08617)
- [x] [Distributed Noisy Networks for Exploration](https://arxiv.org/abs/1706.10295)
- [x] [Distributed Dueling Deep Q-Network](https://arxiv.org/abs/1511.06581)
- [x] [Distributed Double Deep Q-Network](https://arxiv.org/abs/1509.06461)
- [x] [Distributed Deep Q-Network](https://arxiv.org/abs/1312.5602)
- [x] [Distributed Prioritized Experience Replay](https://arxiv.org/abs/1511.05952)
- [x] [Distributed Rainbow](https://arxiv.org/abs/1710.02298)
- [x] [Distributed Proximal Policy Optimization](https://arxiv.org/abs/1707.06347)
- [x] [Distributed Soft Actor Critic](https://arxiv.org/abs/1801.01290)
- [x] [Distributed Twin Delayed Deep Deterministic Policy Gradient](https://arxiv.org/abs/1802.09477)
- [x] [Distributed Distributional Deterministic Policy Gradients](https://arxiv.org/abs/1804.08617)
- [x] [Distributed Noisy Networks for Exploration](https://arxiv.org/abs/1706.10295)



